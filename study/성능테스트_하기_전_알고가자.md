# 0. 목적
- 사용자 응답 시간을 단축하고, 서버 자원을 최적화
- 장애 감지를 위한 임계치 설정

<br>



# 1. 용어 정리

### **성능 테스트**

- 부하 테스트, 스트레스 테스트로도 불림
- when
    - 클라이언트의 요청이 많아짐에 따라 서버가 얼마나 필요할지 알아야 할 때
- what
    - 비효율적으로 동작하는 애플리케이션 개선 ex. gc(Garbage Collection)
    - DB 성능 개선 ex. 인덱스, 데드락
    - 시스템 설계 개선 ex. 비동기적 구조, 서킷 브레이커
- 툴
    - JMeter, Locust, Artillery, K6, nGrinder 등

### **지연시간(Latency)**

- 한 건의 요청이 응답될 때까지 걸리는 시간
- 보통 ms, s 기준

### **처리량(Throughput)**

- 특정 시간 동안 처리할 수 있는 요청의 양
- 주로 tps 단위
    - tps
        - transaction per second
        - 여기서 transaction은 API 요청부터 응답이 이루어질 때까지를 의미
- vs 대역폭
    - 특정 시간 동안 처리할 수 있는 요청의 최대량
    - 네트워크에선 중요하지만, 성능 테스트에서 중요하진 않음
 
<br>

⇒ 보통 성능테스트 목표를 세울 때는 **처리량**과 **지연 시간**을 조합함  

>💡 **초당 3000개의 요청이 들어올 때 99%의 요청이 100ms 미만으로 처리 되어야 함**
> - 초당 3000개의 요청 : 처리량
> - 100ms 미만으로 처리 : 지연시간

<br>

# 2. 물리 자원의 이용

### CPU

- 계산 작업(암호화, 해시화 포함)
- 이미지, 영상 인코딩

### RAM

- 대체로 CPU 사용량에 정비례
- 인스턴스 대량 생성, 캐싱, 컬렉션 객체 등
    - 인스턴스 대량 생성 시, GC 작동으로 인해 다시 CPU와 메모리 사용량이 늘 수 있음
    - 무분별한 인스턴스 생성은 Nope!! 주의하자!

### Disk

- 파일 입출력, 로그 대량 발생
- (DB로부터) 데이터 대량 입출력

<br>

> 💡 사용량도 중요하지만..  
> 메모리와 디스크를 얼마나 사용하느냐도 중요하지만,  
> 그보다 **얼마나 빠르게 연산을 실행할 수 있느냐**가 더 중요하다!

<br>

# 3. 네트워크는 마법이 아니다

### 네트워크 ‘통신’

- API가 클라이언트에서 서버 내부 자원에 도착하고
    1. 데이터베이스를 호출하거나
    2. 다른 API를 이용할 시
    - 네트워크 통신이 발생한다
- 특히 통신 거리가 길수록 시간은 더 오래 걸림

> 💡 같은 스펙의 서버 자원을 한국과 미국에서 이용해봤을 때?  
> 실제로 클라우드상에서 서버 자원의 리전을 한국, 미국으로 각각 설정하고 생성한 적이 있다.  
> 같은 API를 호출하는 데 한국 서버는 1초 이내, 미국 서버는 3~4초 정도 걸리는 경험을 했었다.

- IDC를 이중화하는 경우가 많은데, 이때 네트워크 비용이 증가할 수 있다는 점을 알아두자!

### 네트워크 대역폭과 지연 시간의 관계

- 네트워크 대역폭이 100mb/s인데, 전송하려는 데이터가 150mb/s라면?
- 대역폭을 넘어서는 데이터는 늦게 전송되고, 지연 시간이 길어짐

> 💡 대역폭 때문에..!
> - 대용량의 파일 다운로드 중 인터넷 웹 서핑이 느려짐
> - 고해상도 이미지 많이 포함된 페이지 접속 시 이미지 느리게 로딩

- 대역폭은 가장 대역폭이 낮은 회선에 맞춰짐

<br>

# 4. DB도 애플리케이션이다

1. CPU : 사용자가 원하는 데이터인지 확인
2. 메모리 : 연산할 데이터 준비, 캐싱
3. 디스크 : 데이터 저장

### DB의 지연 시간이 길어지는 경우

1. 많은 요청이 들어올 때
2. 많은 데이터에서 필요한 데이터를 찾아야 할 때
3. 용량이 큰 데이터를 응답해야 할 때
4. 락이 자주 걸릴 때 : 락이 걸리는 만큼 지연시간 발생, 데드락 발생 시 응답 처리되지 않기도 함

### DB 이중화

- 안정적인 서비스 운영을 위해 다른 IDC에 DB를 이중화함
- DB 간의 동기화를 위한 데이터 전송도 대역폭을 차지 → 성능에 영향을 미침
- ‘전용회선’을 이용한다!

<br>

# 5. 스레드 풀과 커넥션 풀

### 스레드 풀

- WAS가 기본적으로 설정한 스레드풀 내의 스레드를 통해 요청을 처리할 수 있음
- 처리량이 많을 시 스레드는 빠르게 고갈될 수 있음
- 스레드가 모두 사용중일 시 Queue에 요청이 대기
- Queue도 꽉 차면 요청은 버려짐
- 그렇다고 스레드를 늘리는 게 무조건 좋은 방법일까?
    - Nope! 서버 자원들 사이의 지나치게 경쟁적인 상태가 될 수 있음
    - 로드 밸런싱을 통해 여러 서버가 트래픽을 받도록 개선하거나
    - 비동기적으로 요청을 처리하는 방식을 고려할 수 있음
- 서버만의 문제는 아니다?
    - 다른 인프라에 의존하고 있을 시 서버를 개선하더라도 트래픽이 증가해 병목 현상이 발생할 수 있음
    - 이 경우 인프라 개선, 시스템 구조 자체의 변경이 필요하기도

### 커넥션 풀

- DB 자원 또한 지나치게 경쟁적인 상태가 될 수 있기 때문에, 최대 커넥션을 제한하고 있음
- 백엔드 어플리케이션 개수가 늘어나도 DB의 커넥션 풀은 똑같다! → 이 부분도 잘 고려해야


> 💡 **점진적인 조정이 중요하다!**  
> 스레드 풀도, 커넥션 풀도 성능 테스트를 진행하며 우리 애플리케이션에 맞는 스펙을 점진적으로 찾아가는 게 중요하다.

<br>
<br>

# 참고  
[백엔드 애플리케이션 성능 테스트하기](https://www.inflearn.com/course/%EB%B0%B1%EC%97%94%EB%93%9C-%EC%95%A0%ED%94%8C%EB%A6%AC%EC%BC%80%EC%9D%B4%EC%85%98-%EC%84%B1%EB%8A%A5-%ED%85%8C%EC%8A%A4%ED%8A%B8)


<개발자 기술 면접 노트>
